{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheong0522/KBSC/blob/main/KBSC_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "dKtucpOxO1hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "metadata": {
        "id": "12zxPlhVOxMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDiS84JrOeKo"
      },
      "outputs": [],
      "source": [
        "!pip install soynlp emoji"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "x420o-RnOfq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6ba84a-3cb0-46f7-cfc7-6b6dd0a6ab41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wTTu1XdYOo80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW \n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "biryssfPOspi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "S1iBnX0mOugA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_excel('/content/drive/MyDrive/KBSC_data.xlsx')"
      ],
      "metadata": {
        "id": "Tz1B0xaXP0tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.loc[(test_data['Emotion'] == \"행복\"), 'Emotion'] = 0 \n",
        "test_data.loc[(test_data['Emotion'] == \"슬픔\"), 'Emotion'] = 1  \n",
        "test_data.loc[(test_data['Emotion'] == \"분노\"), 'Emotion'] = 2  \n",
        "test_data.loc[(test_data['Emotion'] == \"불안\"), 'Emotion'] = 3  \n",
        "test_data.loc[(test_data['Emotion'] == \"중립\"), 'Emotion'] = 4  "
      ],
      "metadata": {
        "id": "-lt9ysBzPxnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = []\n",
        "for sen, label in zip(test_data['Sentence'], test_data['Emotion']):\n",
        "  data_train = []\n",
        "  data_train.append(sen)\n",
        "  data_train.append(str(label))\n",
        "\n",
        "  train_dataset.append(data_train)"
      ],
      "metadata": {
        "id": "ixOALbtKfDwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "  \n",
        "  def __init__(self, dataset):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n",
        "\n",
        "    self.sentences = [str([i[0]]) for i in dataset]\n",
        "    self.labels = [np.int32(i[1]) for i in dataset]\n",
        "\n",
        "  def __len__(self):\n",
        "    return (len(self.labels))\n",
        "  \n",
        "  def __getitem__(self, i):\n",
        "    text = self.sentences[i]\n",
        "    y = self.labels[i]\n",
        "\n",
        "    inputs = self.tokenizer(\n",
        "        text, \n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        max_length=64,\n",
        "        pad_to_max_length=True,\n",
        "        add_special_tokens=True\n",
        "        )\n",
        "    \n",
        "    input_ids = inputs['input_ids'][0]\n",
        "    attention_mask = inputs['attention_mask'][0]\n",
        "\n",
        "    return input_ids, attention_mask, y"
      ],
      "metadata": {
        "id": "Y3fXRgDrfMTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TrainDataset(train_dataset)"
      ],
      "metadata": {
        "id": "NMs10oTYfNRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "model = AutoModel.from_pretrained(\"beomi/KcELECTRA-base\", num_labels=5)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "yMtvldLEQ_1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 1"
      ],
      "metadata": {
        "id": "PgqWr0Du57ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=5, shuffle=True)"
      ],
      "metadata": {
        "id": "wDHKahenfb3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgjUstPbZH2a"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "#정확도 측정을 위한 함수 정의\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for i in range(epochs):\n",
        "  train_acc = 0.0\n",
        "  total_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  batches = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    y_batch = y_batch.long().to(device)\n",
        "    y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
        "    y_pred = y_pred[:, -1, :]\n",
        "    loss = loss_fn(y_pred, y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    train_acc += calc_accuracy(y_pred, y_batch)\n",
        "    total += len(y_batch)\n",
        "\n",
        "    batches += 1\n",
        "    if batches % 50 == 0:\n",
        "      print(\"epoch {} loss {} train acc {}\".format(i+1, loss.data.cpu().numpy(), train_acc / (batches+1)))\n",
        "  print(\"epoch {} loss {} train acc {}\".format(i+1, loss.data.cpu().numpy(), train_acc / (batches+1)))\n",
        "  \n",
        "  model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence):\n",
        "    data = [sentence, '0']\n",
        "    dataset_another = [data]\n",
        "    logits = 0\n",
        "    another_test = TrainDataset(dataset_another)\n",
        "    test_dataloader = torch.utils.data.DataLoader(another_test)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for input_ids_batch, attention_masks_batch, y_batch in test_dataloader:\n",
        "        y_batch = y_batch.long().to(device)\n",
        "        out = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        for i in out:\n",
        "            logits = i\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            logits = np.argmax(logits)\n",
        "    return logits\n",
        "\n",
        "predict(\"짜증나!\")"
      ],
      "metadata": {
        "id": "MeAJLaqJJfkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import socket\n",
        "import time"
      ],
      "metadata": {
        "id": "NFY3PjnR517g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "host = '127.0.01' # 호스트 ip를 적어주세요\n",
        "port = 8080            # 포트번호를 임의로 설정해주세요"
      ],
      "metadata": {
        "id": "cjEWQ7gp6g0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "server_sock = socket.socket(socket.AF_INET)\n",
        "server_sock.bind((host, port))\n",
        "server_sock.listen(1)\n",
        "print(\"기다리는 중..\")"
      ],
      "metadata": {
        "id": "kxRMrFThJztD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True: #안드로이드에서 연결 버튼 누를 때까지 기다림\n",
        "    client_sock, addr = server_sock.accept() # 연결 승인\n",
        "\n",
        "    if client_sock: #client_sock 가 null 값이 아니라면 (연결 승인 되었다면)\n",
        "\n",
        "        print('Connected by?!', addr) #연결주소 print\n",
        "        in_data = client_sock.recv(1024) #안드로이드에서 \"refresh\" 전송\n",
        "        print('rcv :', in_data.decode(\"utf-8\"), len(in_data)) #전송 받은값 디코딩\n",
        "\n",
        "        #밑에 in_data를 일기 내용이라고 생각하고\n",
        "        predict(in_data)\n",
        "\n",
        "        import random\n",
        "        num = random.randint(1,30)\n",
        "        print(num)\n",
        "\n",
        "        if emotion == 0 :\n",
        "          happy_music_data = pd.read_excel('/content/drive/MyDrive/happy_music_data.xlsx')\n",
        "          out_data = happy_music_data.loc[num]\n",
        "        elif emotion == 1 :\n",
        "          sad_music_data = pd.read_excel('/content/drive/MyDrive/sad_music_data.xlsx')\n",
        "          out_data = sad_music_data.loc[num]\n",
        "        elif emotion == 2 :\n",
        "          anger_music_data = pd.read_excel('/content/drive/MyDrive/anger_music_data.xlsx')\n",
        "          out_data = anger_music_data.loc[num]\n",
        "        elif emotion == 3 :\n",
        "          nervous_music_data = pd.read_excel('/content/drive/MyDrive/nervous_music_data.xlsx')\n",
        "          out_data = nervous_music_data.loc[num]\n",
        "        elif emotion == 4 :\n",
        "          neutrality_music_data = pd.read_excel('/content/drive/MyDrive/neutrality_music_data.xlsx')\n",
        "          out_data = neutrality_music_data.loc[num]\n",
        "\n",
        "        while in_data : #2초마다 안드로이드에 값을 전달함 (추후 , STOP , Connect 옵션 설정 가능)\n",
        "            client_sock.send(str(out_data).encode(\"utf-8\")) # string 으로 인코딩해서 전송, byte 로 전송하면 복잡함\n",
        "           \n",
        "            print('send :', out_data) #아웃 데이터에 넣어야함 노래 제목이나 감정 수치 넣어야함\n",
        "\n",
        "            #서버에 2초마다 데이터 전송\n",
        "            time.sleep(2)"
      ],
      "metadata": {
        "id": "ATT7V1srJzvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_sock.close()\n",
        "server_sock.close()"
      ],
      "metadata": {
        "id": "kapWgRPbJzxQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}